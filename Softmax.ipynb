{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164da3d5-8c3b-44de-9e9a-b557fd673a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b67a3-f2ae-4b42-92b9-2f081e79d3f7",
   "metadata": {},
   "source": [
    "#### La funzione softmax prende un vettore e tutti i suoi elementi iesimi vengono considerati come e elevato al suo stesso elemento fratto la sommatoria di e eleveato al singolo elemento di tutti quanti gli elementi iesimi      eyi / Æ©eyi\n",
    "* Creo due liste x_big e y su una costante (K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b335a5-b53a-45bc-8e3a-612cd5c5171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_big = []\n",
    "y = []\n",
    "\n",
    "features = 10 \n",
    "k = 1000000\n",
    "for i in range(10000):\n",
    "    new_example_big = np.random.random(10) * k\n",
    "    x_big.append(new_example_big)\n",
    "    new_label = [0] * features\n",
    "    new_label[np.argmax(new_example_big)] = 1\n",
    "    y.append(new_label)\n",
    "\n",
    "x_big = np.asarray(x_big, dtype= np.float32)\n",
    "y = np.asarray(y, dtype= np.float32)\n",
    "x = x_big / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825f1e98-9b6c-4613-9af5-15dd4f6924f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35482047 0.35230906 0.21783502 0.34122713 0.32676266 0.35023675\n",
      " 0.09149178 0.65687669 0.71502369 0.839276  ]\n",
      "[354820.47 352309.06 217835.02 341227.12 326762.66 350236.75  91491.78\n",
      " 656876.7  715023.7  839276.  ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(x[42])\n",
    "print(x_big[42])\n",
    "print(y[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e75b38a-4ada-4347-9fe0-200fdf80bba0",
   "metadata": {},
   "source": [
    "#### Addestro il modello con x per vedere le differenze tra l'output tra un dataset con dati normalizzati e con dati di grandi dimensioni e come noteremo con lo stesso dataset la softmax ci dara dei migliori risultati sui dati normalizzati (il modello sara addestrato per darci la posizione giusta per l'elemento piu grande del nostro dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5c4490-4241-4b76-b31d-3c3af9559a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                110       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 220 (880.00 Byte)\n",
      "Trainable params: 220 (880.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05264868959784508"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Input(shape=(features))\n",
    "dense = Dense(features, activation = 'swish')(input)\n",
    "dense = Dense(features, activation = 'softmax')(dense)\n",
    "\n",
    "model = Model(inputs= input, outputs = dense)\n",
    "\n",
    "model.compile(optimizer = Adam(), loss = MeanSquaredError())\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x[:9000], \n",
    "    y[:9000],\n",
    "    epochs= 10,\n",
    "    batch_size = 32,\n",
    "    verbose=0\n",
    ")\n",
    "model.evaluate(x[9000:],y[9000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07139d37-5b56-424f-8dc8-260cc9d11f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 220 (880.00 Byte)\n",
      "Trainable params: 220 (880.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05999999865889549"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Input(shape=(features))\n",
    "dense = Dense(features, activation = 'swish')(input)\n",
    "dense = Dense(features, activation = 'softmax')(dense)\n",
    "\n",
    "model = Model(inputs= input, outputs = dense)\n",
    "\n",
    "model.compile(optimizer = Adam(), loss = MeanSquaredError())\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x[:9000], \n",
    "    y[:9000],\n",
    "    epochs= 10,\n",
    "    batch_size = 32,\n",
    "    verbose=0\n",
    ")\n",
    "model.evaluate(x_big[9000:],y[9000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d089a-d66e-4b47-928d-2d4f9813e767",
   "metadata": {},
   "source": [
    "#### Formula softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f522da4-90f1-4ddb-bfed-8288010f44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exps = np.exp(x)\n",
    "    return exps / np.sum(exps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5171e-c69c-4f8b-acce-a998defa14d2",
   "metadata": {},
   "source": [
    "#### Come possiamo vedere con numeri grandi va in overflow e crea qualcosa che diventa un NaN e viene riscontrato anche con la divisione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd96e59c-f482-4836-b910-bb7bdf05ff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09089446 0.09066648 0.07925842 0.08966726 0.08837961 0.09047878\n",
      " 0.06985142 0.12294724 0.13030818 0.14754816]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_1388\\1135684835.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  exps = np.exp(x)\n",
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_1388\\1135684835.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  return exps / np.sum(exps)\n"
     ]
    }
   ],
   "source": [
    "print(softmax(x[42]))\n",
    "print(softmax(x_big[42]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f42a9f-a624-4b96-91c2-918181b50346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
